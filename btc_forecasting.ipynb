{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Bitcoin data\n",
    "data = pd.read_csv('data/BTC_data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data     \n",
    "\n",
    "The next step in the notebook will be preprocessing the data. Preprocessing might include handling missing values, normalizing data, and removing unwanted columns.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Normalize the 'Close' prices to a range of 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data['Close'] = scaler.fit_transform(data[['Close']])\n",
    "\n",
    "# Display the cleaned data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:         \n",
    "\n",
    "- *dropna():* Removes rows with missing values.         \n",
    "- *MinMaxScaler:* This function from sklearn scales the data to be between 0 and 1, which helps the neural network during training.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the tf.data.Dataset for Model Inputs     \n",
    "\n",
    "Next, we’ll use TensorFlow’s tf.data.Dataset to prepare the data for the model. This is how we can structure our time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create dataset for time series prediction\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        X.append(data[i:(i+time_step), 0])\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data['Close'].values.reshape(-1,1)\n",
    "\n",
    "# Set time step to 60 (meaning we'll look at 60 previous days to predict the next one)\n",
    "time_step = 60\n",
    "X, y = create_dataset(dataset, time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:    \n",
    "\n",
    "We’re splitting the data into inputs (X) and outputs (y), where X is a sequence of past values and y is the next value we want to predict.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture       \n",
    "\n",
    "We’ll use an LSTM (Long Short-Term Memory) model, which is great for handling time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(50, return_sequences=True, input_shape=(time_step, 1)),\n",
    "    tf.keras.layers.LSTM(50, return_sequences=False),\n",
    "    tf.keras.layers.Dense(25),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:   \n",
    "\n",
    "- *LSTM:* A type of RNN that helps in capturing patterns in time series data.     \n",
    "- *Dense:* A fully connected layer that outputs the predicted value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Evaluation    \n",
    "A\n",
    "fter training the model, let's evaluate its performance and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Inverse scaling to get actual price predictions\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(data['Close'].values)\n",
    "plt.plot(predictions)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
